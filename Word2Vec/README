==========================================================================================

         Introduction to Natural Laguage Processing Assignment 1
 
==========================================================================================

# Task 1: Generating Batches for words.
In the "word2vec_basic.py" file, we wrote the implementation of "generate_batch" to generate the batches. Batches are generated by extracting the words on the left and right of context words. For this to happen we need to ensure that the minimum number of words are present on both sides of the context word. We ensure this by starting at the skip_window index and continue sampling batches until we reach the intended number of batches.

# Task 2: Cross Entropy implementation.
In the loss_func.py we implement the cross_entropy_loss function. We do this using the context and target word embeddings and using the given formula. In the implementation, we need to perform an additional step where we remove nan values from the tensor and replace it with zeroes. This was unavoidable as the nan values were encountered immediately upon calculating the dot product.

# Task 3: NCE loss function.
In the loss_func.py we implement the nce_loss function. We do this using the context, target and negative sample word embeddings and using the given formula. In the implementation, we need to perform an additional step where we add a small value to the tensors before taking the log of the tensor to ensure that we dont get Nan values.

# The configurations for the submitted model are as follows
batch_size = 128
embedding_size = 128
skip_window = 4
num_skips = 8

max_num_steps  = 300001
checkpoint_step = 50000

# File names and contents of files
word2vec_basic.py - The given word2vec python file.
loss_func.py - File containing loss function implementations.
word_analogy.py - File containing implementation of word analogy task.
word_analogy_cross_entropy.txt - File containing the results of the analogy tasks using the cross entropy model.
word_analogy_nce.txt - File containing the results of the analogy tasks using the nce loss model.
word_analogy_cross_entropy_results.txt - File containing the accuracy stats for the cross_entropy analogy task.
word_analogy_nce_results.txt - File containing the accuracy stats for the nce analogy task.
